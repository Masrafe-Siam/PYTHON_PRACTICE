{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "283a6acf",
   "metadata": {},
   "source": [
    "## 1–2) Acquire & Load MNIST into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ef8311a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>px_0</th>\n",
       "      <th>px_1</th>\n",
       "      <th>px_2</th>\n",
       "      <th>px_3</th>\n",
       "      <th>px_4</th>\n",
       "      <th>px_5</th>\n",
       "      <th>px_6</th>\n",
       "      <th>px_7</th>\n",
       "      <th>px_8</th>\n",
       "      <th>px_9</th>\n",
       "      <th>...</th>\n",
       "      <th>px_775</th>\n",
       "      <th>px_776</th>\n",
       "      <th>px_777</th>\n",
       "      <th>px_778</th>\n",
       "      <th>px_779</th>\n",
       "      <th>px_780</th>\n",
       "      <th>px_781</th>\n",
       "      <th>px_782</th>\n",
       "      <th>px_783</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   px_0  px_1  px_2  px_3  px_4  px_5  px_6  px_7  px_8  px_9  ...  px_775  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...     0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...     0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...     0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...     0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...     0.0   \n",
       "\n",
       "   px_776  px_777  px_778  px_779  px_780  px_781  px_782  px_783  label  \n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0      5  \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0      0  \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0      4  \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0      1  \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0      9  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "def get_mnist():\n",
    "    \"\"\"Download MNIST 70k from OpenML and return X, y as numpy arrays.\n",
    "    X: (70000, 784) float32; y: (70000,) strings '0'..'9'.\n",
    "    \"\"\"\n",
    "    mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='pandas')\n",
    "    X = mnist['data'].astype(np.float32)\n",
    "    y = mnist['target'].astype(str)\n",
    "    return X, y\n",
    "\n",
    "def to_dataframe(X, y):\n",
    "    cols = [f\"px_{i}\" for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=cols)\n",
    "    df['label'] = y\n",
    "    return df\n",
    "\n",
    "X, y = get_mnist()\n",
    "df = to_dataframe(X, y)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08209a6",
   "metadata": {},
   "source": [
    "## 3) Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bedb44fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Summary ===\n",
      "Total samples: 70000\n",
      "Total features (pixels): 784\n",
      "Target classes: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "\n",
      "Class distribution (counts):\n",
      "label\n",
      "0    6903\n",
      "1    7877\n",
      "2    6990\n",
      "3    7141\n",
      "4    6824\n",
      "5    6313\n",
      "6    6876\n",
      "7    7293\n",
      "8    6825\n",
      "9    6958\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def summarize(df):\n",
    "    n_samples = df.shape[0]\n",
    "    n_features = df.shape[1] - 1\n",
    "    classes = sorted(df['label'].unique().tolist())\n",
    "    print(\"\\n=== Data Summary ===\")\n",
    "    print(f\"Total samples: {n_samples}\")\n",
    "    print(f\"Total features (pixels): {n_features}\")\n",
    "    print(f\"Target classes: {classes}\")    \n",
    "    print(\"\\nClass distribution (counts):\")\n",
    "    print(df['label'].value_counts().sort_index())\n",
    "\n",
    "summarize(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5051e876",
   "metadata": {},
   "source": [
    "## 4) Visualization — Sample Digit Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c62de747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def show_sample_digits(X, y, n=12, title=\"MNIST – sample digits\"):\n",
    "    assert X.shape[1] == 784, \"Expected flattened 28x28 images.\"\n",
    "    n = min(n, X.shape[0])\n",
    "    cols = 6\n",
    "    rows = int(np.ceil(n / cols))\n",
    "    plt.figure(figsize=(cols*2, rows*2))\n",
    "    for i in range(n):\n",
    "        img = X[i].reshape(28, 28)\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(str(y[i]))\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_sample_digits(X, y, n=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad94ae",
   "metadata": {},
   "source": [
    "## 5) Preprocessing — Train/Test Split & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "846684ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56000, 784), (14000, 784))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess(X, y, test_size=0.2, random_state=RANDOM_STATE):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler = preprocess(X, y, test_size=0.2)\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90610ff5",
   "metadata": {},
   "source": [
    "## 6) Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73069659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logreg', 'svm_linear', 'dtree']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC  # linear SVM (fast for high dims)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def make_models():\n",
    "    models = {\n",
    "        \"logreg\": LogisticRegression(\n",
    "            multi_class=\"multinomial\", solver=\"saga\", max_iter=2000, random_state=RANDOM_STATE, n_jobs=-1\n",
    "        ),\n",
    "        \"svm_linear\": LinearSVC(random_state=RANDOM_STATE),\n",
    "        \"dtree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    }\n",
    "    return models\n",
    "\n",
    "models = make_models()\n",
    "list(models.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ff4e0",
   "metadata": {},
   "source": [
    "## 7) Hyperparameter Tuning (Grid Search with Stratified K-Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ed4c52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Tuning logreg ...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best params for logreg: {'C': 1.0, 'penalty': 'l1'}\n",
      "Best CV accuracy for logreg: 0.9197\n",
      "\n",
      ">>> Tuning svm_linear ...\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest CV accuracy for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgs\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tuned, best_estimators\n\u001b[1;32m---> 28\u001b[0m tuned, best_estimators \u001b[38;5;241m=\u001b[39m tune_models(models, X_train, y_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     29\u001b[0m best_estimators\n",
      "Cell \u001b[1;32mIn[6], line 21\u001b[0m, in \u001b[0;36mtune_models\u001b[1;34m(models, X_train, y_train, cv)\u001b[0m\n\u001b[0;32m     19\u001b[0m params \u001b[38;5;241m=\u001b[39m get_param_grids()[name]\n\u001b[0;32m     20\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(model, params, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39mskf, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m gs\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     22\u001b[0m tuned[name] \u001b[38;5;241m=\u001b[39m gs\n\u001b[0;32m     23\u001b[0m best_estimators[name] \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32md:\\Masrafe\\Coding\\python\\anaconda\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Masrafe\\Coding\\python\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Masrafe\\Coding\\python\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32md:\\Masrafe\\Coding\\python\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     )\n\u001b[1;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    966\u001b[0m         clone(base_estimator),\n\u001b[0;32m    967\u001b[0m         X,\n\u001b[0;32m    968\u001b[0m         y,\n\u001b[0;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    975\u001b[0m     )\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m     )\n",
      "File \u001b[1;32md:\\Masrafe\\Coding\\python\\anaconda\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32md:\\Masrafe\\Coding\\python\\anaconda\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32md:\\Masrafe\\Coding\\python\\anaconda\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Masrafe\\Coding\\python\\anaconda\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "def get_param_grids():\n",
    "    return {\n",
    "        \"logreg\": {\"C\": [0.1, 0.5, 1.0, 2.0], \"penalty\": [\"l2\", \"l1\"]},\n",
    "        \"svm_linear\": {\"C\": [0.5, 1.0, 2.0]},\n",
    "        \"dtree\": {\n",
    "            \"max_depth\": [None, 10, 20, 30],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 2, 4],\n",
    "        },\n",
    "    }\n",
    "\n",
    "def tune_models(models, X_train, y_train, cv=3):\n",
    "    tuned, best_estimators = {}, {}\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n>>> Tuning {name} ...\")\n",
    "        params = get_param_grids()[name]\n",
    "        gs = GridSearchCV(model, params, scoring=\"accuracy\", n_jobs=-1, cv=skf, verbose=1)\n",
    "        gs.fit(X_train, y_train)\n",
    "        tuned[name] = gs\n",
    "        best_estimators[name] = gs.best_estimator_\n",
    "        print(f\"Best params for {name}: {gs.best_params_}\")\n",
    "        print(f\"Best CV accuracy for {name}: {gs.best_score_:.4f}\")\n",
    "    return tuned, best_estimators\n",
    "\n",
    "tuned, best_estimators = tune_models(models, X_train, y_train, cv=3)\n",
    "best_estimators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c7c62e",
   "metadata": {},
   "source": [
    "## 8) Training Evaluation (Confusion Matrix, Accuracy, Precision, Recall, F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe89097",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "def evaluate(model, X, y, title=\"Evaluation\"):\n",
    "    y_pred = model.predict(X)\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    prec_w, rec_w, f1_w, _ = precision_recall_fscore_support(y, y_pred, average='weighted', zero_division=0)\n",
    "    prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(y, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification report (weighted):\")\n",
    "    print(classification_report(y, y_pred, digits=4))\n",
    "\n",
    "    cm = confusion_matrix(y, y_pred, labels=[str(i) for i in range(10)])\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision_weighted\": prec_w,\n",
    "        \"recall_weighted\": rec_w,\n",
    "        \"f1_weighted\": f1_w,\n",
    "        \"precision_macro\": prec_m,\n",
    "        \"recall_macro\": rec_m,\n",
    "        \"f1_macro\": f1_m,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"y_pred\": y_pred,\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, title):\n",
    "    plt.figure(figsize=(7,6))\n",
    "    plt.imshow(cm, aspect='auto')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.colorbar()\n",
    "    plt.xticks(ticks=range(len(labels)), labels=labels)\n",
    "    plt.yticks(ticks=range(len(labels)), labels=labels)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "train_results = {}\n",
    "for name, est in best_estimators.items():\n",
    "    train_results[name] = evaluate(est, X_train, y_train, title=f\"{name} – Train\")\n",
    "train_results.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71b6730",
   "metadata": {},
   "source": [
    "## 9) Testing Evaluation + Bootstrap 95% Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda2ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_results = {}\n",
    "for name, est in best_estimators.items():\n",
    "    test_results[name] = evaluate(est, X_test, y_test, title=f\"{name} – Test\")\n",
    "    labels = [str(i) for i in range(10)]\n",
    "    plot_confusion_matrix(test_results[name]['confusion_matrix'], labels, f\"{name} – Test Confusion Matrix\")\n",
    "\n",
    "def bootstrap_metrics(model, X_test, y_test, n_boot=300, random_state=RANDOM_STATE):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    N = len(y_test)\n",
    "    accs, precs, recs, f1s = [], [], [], []\n",
    "    for _ in tqdm(range(n_boot), desc=\"Bootstrapping\"):\n",
    "        idx = rng.integers(0, N, size=N)\n",
    "        y_true_b = np.array(y_test)[idx]\n",
    "        y_pred_b = model.predict(X_test[idx])\n",
    "        accs.append(accuracy_score(y_true_b, y_pred_b))\n",
    "        p, r, f1, _ = precision_recall_fscore_support(y_true_b, y_pred_b, average='weighted', zero_division=0)\n",
    "        precs.append(p); recs.append(r); f1s.append(f1)\n",
    "    def ci(a):\n",
    "        lo, hi = np.percentile(a, [2.5, 97.5])\n",
    "        return float(np.mean(a)), float(lo), float(hi)\n",
    "    return {\n",
    "        \"accuracy_mean_ci\": ci(accs),\n",
    "        \"precision_weighted_mean_ci\": ci(precs),\n",
    "        \"recall_weighted_mean_ci\": ci(recs),\n",
    "        \"f1_weighted_mean_ci\": ci(f1s),\n",
    "    }\n",
    "\n",
    "test_bootstrap = {name: bootstrap_metrics(est, X_test, y_test, n_boot=300) for name, est in best_estimators.items()}\n",
    "\n",
    "print(\"\\n=== Bootstrapped 95% CIs on Test (mean, 2.5%, 97.5%) ===\")\n",
    "for name, summ in test_bootstrap.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    for k, v in summ.items():\n",
    "        mean, lo, hi = v\n",
    "        print(f\"  {k}: mean={mean:.4f}, 95% CI=({lo:.4f}, {hi:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f58de6",
   "metadata": {},
   "source": [
    "## 10) Model Comparison & Over/Underfitting Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d2a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_models(train_results, test_results):\n",
    "    rows = []\n",
    "    for name in test_results.keys():\n",
    "        tr = train_results[name]; te = test_results[name]\n",
    "        rows.append({\n",
    "            \"model\": name,\n",
    "            \"train_acc\": tr['accuracy'],\n",
    "            \"test_acc\": te['accuracy'],\n",
    "            \"train_f1_w\": tr['f1_weighted'],\n",
    "            \"test_f1_w\": te['f1_weighted'],\n",
    "        })\n",
    "    df = pd.DataFrame(rows).sort_values(\"test_acc\", ascending=False)\n",
    "    print(\"\\n=== Model Comparison (sorted by test accuracy) ===\")\n",
    "    print(df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "    print(\"\\nNotes on potential over/underfitting:\")\n",
    "    for _, r in df.iterrows():\n",
    "        gap = r['train_acc'] - r['test_acc']\n",
    "        note = \"balanced fit\"\n",
    "        if gap > 0.05:\n",
    "            note = \"possible overfitting (large train-test gap)\"\n",
    "            # if test accuracy is also low, emphasize underperformance\n",
    "            if r['test_acc'] < 0.85:\n",
    "                note += \"; also underperforming on test\"\n",
    "        elif r['train_acc'] < 0.85 and r['test_acc'] < 0.85:\n",
    "            note = \"possible underfitting (both low)\"\n",
    "        print(f\"- {r['model']}: gap={gap:.3f} → {note}\")\n",
    "\n",
    "compare_models(train_results, test_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, random, math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "\n",
    "# inline plots\n",
    "%matplotlib inline\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f8788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "IMG_H, IMG_W = 32, 32\n",
    "NUM_CLASSES = 3\n",
    "CHANNELS = 1\n",
    "VARIANTS_PER_CLASS = 24          # >= 20 (change if you want more)\n",
    "TEST_PER_CLASS = 4               # held-out test count per class\n",
    "VAL_SPLIT = 0.2                  # from remaining after taking test\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Optimizer / LR grid\n",
    "OPTIMIZERS = ['adam', 'sgd']\n",
    "LRS = [1e-3, 1e-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4403b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_gray(path):\n",
    "    # Load grayscale PNG to (H,W,1) float32 in [0,1].\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)  # [0,1]\n",
    "    img = tf.image.resize(img, (IMG_H, IMG_W), method='nearest')\n",
    "    return img\n",
    "\n",
    "def show_seeds(imgs, labels):\n",
    "    plt.figure(figsize=(6,2))\n",
    "    for i, (im, lb) in enumerate(zip(imgs, labels)):\n",
    "        plt.subplot(1,3,i+1)\n",
    "        plt.imshow(tf.squeeze(im), cmap='gray')\n",
    "        plt.title(f'label {lb}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b936f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- lightweight TensorFlow equivalents for rotate/translate to avoid tensorflow-addons dependency ----\n",
    "def tfa_image_rotate(img, radians):\n",
    "    c = tf.math.cos(radians)\n",
    "    s = tf.math.sin(radians)\n",
    "    h, w = IMG_H, IMG_W\n",
    "    cx, cy = (w - 1) / 2.0, (h - 1) / 2.0\n",
    "    tx = cx - c * cx + s * cy\n",
    "    ty = cy - s * cx - c * cy\n",
    "    transform = tf.stack([c, -s, tx, s, c, ty, 0.0, 0.0])\n",
    "    transform = tf.reshape(transform, (1, 8))\n",
    "    img_b = tf.expand_dims(img, 0)\n",
    "    out = tf.raw_ops.ImageProjectiveTransformV3(\n",
    "        images=img_b,\n",
    "        transforms=transform,\n",
    "        fill_mode='REFLECT',\n",
    "        interpolation='BILINEAR',\n",
    "        output_shape=[h, w]\n",
    "    )\n",
    "    return tf.squeeze(out, 0)\n",
    "\n",
    "def tfa_image_translate(img, deltas_xy):\n",
    "    dx, dy = deltas_xy[0], deltas_xy[1]\n",
    "    transform = tf.stack([1.0, 0.0, -dx, 0.0, 1.0, -dy, 0.0, 0.0])\n",
    "    transform = tf.reshape(transform, (1, 8))\n",
    "    img_b = tf.expand_dims(img, 0)\n",
    "    out = tf.raw_ops.ImageProjectiveTransformV3(\n",
    "        images=img_b,\n",
    "        transforms=transform,\n",
    "        fill_mode='REFLECT',\n",
    "        interpolation='BILINEAR',\n",
    "        output_shape=[IMG_H, IMG_W]\n",
    "    )\n",
    "    return tf.squeeze(out, 0)\n",
    "\n",
    "def random_zoom_keep_size(img, zoom):\n",
    "    h, w = IMG_H, IMG_W\n",
    "    if zoom > 1.0:\n",
    "        new_h = tf.cast(tf.round(h / zoom), tf.int32)\n",
    "        new_w = tf.cast(tf.round(w / zoom), tf.int32)\n",
    "        top = (h - new_h) // 2\n",
    "        left = (w - new_w) // 2\n",
    "        cropped = img[top:top+new_h, left:left+new_w, :]\n",
    "        return tf.image.resize(cropped, (h, w), method='bilinear')\n",
    "    else:\n",
    "        new_h = tf.cast(tf.round(h * zoom), tf.int32)\n",
    "        new_w = tf.cast(tf.round(w * zoom), tf.int32)\n",
    "        resized = tf.image.resize(img, (new_h, new_w), method='bilinear')\n",
    "        pad_top = (h - new_h) // 2\n",
    "        pad_bottom = h - new_h - pad_top\n",
    "        pad_left = (w - new_w) // 2\n",
    "        pad_right = w - new_w - pad_left\n",
    "        padded = tf.pad(resized, [[pad_top, pad_bottom],[pad_left, pad_right],[0,0]], mode='REFLECT')\n",
    "        return tf.image.resize(padded, (h, w), method='bilinear')\n",
    "\n",
    "@tf.function\n",
    "def augment_once(x):\n",
    "    # random rotation ±15°\n",
    "    angle = tf.random.uniform([], minval=-15.0, maxval=15.0) * math.pi / 180.0\n",
    "    x = tfa_image_rotate(x, angle)\n",
    "\n",
    "    # small translations ±3px\n",
    "    tx = tf.random.uniform([], -3.0, 3.0)\n",
    "    ty = tf.random.uniform([], -3.0, 3.0)\n",
    "    x = tfa_image_translate(x, [tx, ty])\n",
    "\n",
    "    # random zoom/crop (0.9–1.1)\n",
    "    zoom = tf.random.uniform([], 0.9, 1.1)\n",
    "    x = random_zoom_keep_size(x, zoom)\n",
    "\n",
    "    # optional flip (set to low prob for digits)\n",
    "    if tf.random.uniform([]) < 0.3:\n",
    "        x = tf.image.flip_left_right(x)\n",
    "\n",
    "    # brightness/contrast jitter\n",
    "    x = tf.image.random_brightness(x, max_delta=0.15)\n",
    "    x = tf.image.random_contrast(x, lower=0.8, upper=1.2)\n",
    "\n",
    "    # Gaussian noise\n",
    "    noise = tf.random.normal(tf.shape(x), mean=0.0, stddev=0.03)\n",
    "    x = tf.clip_by_value(x + noise, 0.0, 1.0)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b8192",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_dataset(seed_paths):\n",
    "    seeds, labels = [], []\n",
    "    for p, lb in seed_paths:\n",
    "        assert os.path.exists(p), f'Missing file: {p}'\n",
    "        img = load_gray(p)\n",
    "        seeds.append(img)\n",
    "        labels.append(lb)\n",
    "\n",
    "    # Show seeds\n",
    "    show_seeds(seeds, labels)\n",
    "\n",
    "    X, y = [], []\n",
    "    for img, lb in zip(seeds, labels):\n",
    "        # include the original too\n",
    "        X.append(img.numpy())\n",
    "        y.append(lb)\n",
    "        for _ in range(VARIANTS_PER_CLASS):\n",
    "            X.append(augment_once(img).numpy())\n",
    "            y.append(lb)\n",
    "\n",
    "    X = np.stack(X, axis=0).astype('float32')\n",
    "    y = np.array(y, dtype=np.int32)\n",
    "    return X, y\n",
    "\n",
    "# Define your seed paths here (update if needed)\n",
    "seed_paths = [\n",
    "    ('zero_0.png', 0),\n",
    "    ('one_0.png', 1),\n",
    "    ('two_0.png', 2),\n",
    "]\n",
    "\n",
    "X, y = make_dataset(seed_paths)\n",
    "print('Dataset shape:', X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_dataset(X, y, num_classes=NUM_CLASSES, test_per_class=TEST_PER_CLASS, val_split=VAL_SPLIT):\n",
    "    Xc, yc = [], []\n",
    "    testX, testy = [], []\n",
    "    for c in range(num_classes):\n",
    "        idx = np.where(y == c)[0]\n",
    "        np.random.shuffle(idx)\n",
    "        test_take = idx[:test_per_class]\n",
    "        keep = idx[test_per_class:]\n",
    "        testX.append(X[test_take])\n",
    "        testy.append(y[test_take])\n",
    "        Xc.append(X[keep])\n",
    "        yc.append(y[keep])\n",
    "    X_keep = np.concatenate(Xc, axis=0)\n",
    "    y_keep = np.concatenate(yc, axis=0)\n",
    "    X_test = np.concatenate(testX, axis=0)\n",
    "    y_test = np.concatenate(testy, axis=0)\n",
    "\n",
    "    perm = np.random.permutation(len(X_keep))\n",
    "    X_keep, y_keep = X_keep[perm], y_keep[perm]\n",
    "    n_val = int(len(X_keep) * val_split)\n",
    "    X_val, y_val = X_keep[:n_val], y_keep[:n_val]\n",
    "    X_train, y_train = X_keep[n_val:], y_keep[n_val:]\n",
    "\n",
    "    print(f'Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}')\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_dataset(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(IMG_H, IMG_W, CHANNELS)),\n",
    "        layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax'),\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cfe9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_grid(X_train, y_train, X_val, y_val, optimizers=OPTIMIZERS, lrs=LRS):\n",
    "    best = {'val_acc': -1.0, 'history': None, 'model': None, 'opt_name': None, 'lr': None}\n",
    "    y_train_cat = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "    y_val_cat = keras.utils.to_categorical(y_val, NUM_CLASSES)\n",
    "\n",
    "    for opt_name in optimizers:\n",
    "        for lr in lrs:\n",
    "            model = build_model()\n",
    "            if opt_name == 'adam':\n",
    "                opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "            elif opt_name == 'sgd':\n",
    "                opt = keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "            else:\n",
    "                raise ValueError('Unknown optimizer')\n",
    "\n",
    "            model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            print(f'=== Training with {opt_name.upper()} lr={lr} ===')\n",
    "            hist = model.fit(\n",
    "                X_train, y_train_cat,\n",
    "                validation_data=(X_val, y_val_cat),\n",
    "                epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0\n",
    "            )\n",
    "            val_acc = max(hist.history['val_accuracy'])\n",
    "            print(f'Max val_acc: {val_acc:.4f}')\n",
    "            if val_acc > best['val_acc']:\n",
    "                best.update({'val_acc': val_acc, 'history': hist, 'model': model, 'opt_name': opt_name, 'lr': lr})\n",
    "    return best\n",
    "\n",
    "best = train_grid(X_train, y_train, X_val, y_val)\n",
    "print(f\"Best setting -> optimizer: {best['opt_name']}, lr: {best['lr']}, best_val_acc: {best['val_acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b0388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_accuracy(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    epochs = np.arange(1, len(acc)+1)\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.plot(epochs, acc, label='train acc')\n",
    "    plt.plot(epochs, val_acc, label='val acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Train vs. Val Accuracy (best run)')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_accuracy(best['history'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confmat(cm, class_names=('0','1','2')):\n",
    "    plt.figure(figsize=(3.8,3.2))\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    thresh = cm.max() / 2.0 if cm.max() > 0 else 0.5\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     horizontalalignment='center',\n",
    "                     color='white' if cm[i, j] > thresh else 'black')\n",
    "    plt.ylabel('True')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "model = best['model']\n",
    "y_pred_prob = model.predict(X_test, batch_size=64, verbose=0)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "print('=== Test Metrics ===')\n",
    "print(f'Accuracy:  {acc:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall:    {recall:.4f}')\n",
    "print(f'F1 (macro):{f1:.4f}')\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1,2])\n",
    "print('\\nConfusion Matrix:\\n', cm)\n",
    "plot_confmat(cm, class_names=('0','1','2'))\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cdeed8",
   "metadata": {},
   "source": [
    "\n",
    "### Short Summary (fill with your actual results)\n",
    "- **Best setting:** *(e.g., Adam @ 1e-3)* achieved the highest validation accuracy with stable learning curves.\n",
    "- **Generalization:** Test **F1 (macro)** ≈ *…*; most confusion between *1 ↔ 2* (expected with tiny data).\n",
    "- **Fit signs:** Slight overfitting after epoch ~… (train↑, val↔/↓). Consider stronger augmentation or early stopping.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DS 424 — Lab Final (Topic A)\n",
        "ID:221-35-938\n",
        "\n",
        "## Student Exam Result (Tabular Classification)\n",
        "Followed exactly as in the brief: load & inspect, EDA (≥2 plots), split 80/20, standardize, build a compact ANN (two optimizers × two learning rates, ≤20 epochs), evaluate on test (accuracy, precision, recall, F1) and plot confusion matrix, plus a 3–5 line conclusion.\n",
        "\n",
        "> If `student_performance.csv` is missing, this notebook will create a synthetic dataset with similar semantics so you can run end-to-end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "print('TensorFlow:', tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1) Load & Inspect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "csv_path = 'student_performance.csv'\n",
        "if not os.path.exists(csv_path):\n",
        "    rng = np.random.default_rng(42)\n",
        "    n = 300\n",
        "    hours = rng.uniform(0, 10, size=n)\n",
        "    attendance = rng.uniform(50, 100, size=n)\n",
        "    prev = rng.uniform(0, 100, size=n)\n",
        "    sleep = rng.uniform(4, 9, size=n)\n",
        "    logits = 0.6*hours + 0.04*attendance + 0.03*prev - 0.1*(8 - sleep) + rng.normal(0,1,n)\n",
        "    y = (logits > np.median(logits)).astype(int)\n",
        "    df = pd.DataFrame({\n",
        "        'Hours_Study': hours,\n",
        "        'Attendance': attendance,\n",
        "        'Previous_Score': prev,\n",
        "        'Sleep_Hours': sleep,\n",
        "        'Exam_Result': y\n",
        "    })\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"[INFO] '{csv_path}' not found. Created a synthetic dataset with shape {df.shape}.\")\n",
        "else:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"[INFO] Loaded '{csv_path}' with shape {df.shape}.\")\n",
        "display(df.head())\n",
        "print('\\nShape:', df.shape)\n",
        "print('\\nDtypes:\\n', df.dtypes)\n",
        "print('\\nMissing values per column:\\n', df.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2) EDA — Two Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(df['Hours_Study'], bins=20)\n",
        "plt.title('Histogram: Hours_Study')\n",
        "plt.xlabel('Hours_Study'); plt.ylabel('Count')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "scatter = plt.scatter(df['Hours_Study'], df['Attendance'], c=df['Exam_Result'], s=20)\n",
        "plt.title('Hours_Study vs Attendance (colored by Exam_Result)')\n",
        "plt.xlabel('Hours_Study'); plt.ylabel('Attendance (%)')\n",
        "plt.legend(*scatter.legend_elements(), title='Exam_Result', loc='best')\n",
        "plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3) Preprocess — Train/Test Split + Standardize Numeric Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target = 'Exam_Result'\n",
        "feature_cols = [c for c in df.columns if c != target]\n",
        "X = df[feature_cols].values.astype('float32')\n",
        "y = df[target].values.astype('int32')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train).astype('float32')\n",
        "X_test_scaled  = scaler.transform(X_test).astype('float32')\n",
        "print('Train shape:', X_train_scaled.shape, ' Test shape:', X_test_scaled.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4) Modeling — Compact Keras ANN; Optimizers × Learning Rates (≤20 epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_ann(input_dim: int, lr: float=1e-3, optimizer_name: str='adam'):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Input(shape=(input_dim,)),\n",
        "        keras.layers.Dense(16, activation='relu'),\n",
        "        keras.layers.Dense(8, activation='relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    if optimizer_name.lower() == 'adam':\n",
        "        opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "    else:\n",
        "        opt = keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "configs = [('adam',1e-3), ('adam',1e-2), ('sgd',1e-3), ('sgd',1e-2)]\n",
        "results = []\n",
        "for opt_name, lr in configs:\n",
        "    model = build_ann(X_train_scaled.shape[1], lr=lr, optimizer_name=opt_name)\n",
        "    h = model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=20, batch_size=32, verbose=0)\n",
        "    proba = model.predict(X_test_scaled, verbose=0).ravel()\n",
        "    y_pred = (proba >= 0.5).astype(int)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', zero_division=0)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    results.append({'optimizer':opt_name,'lr':lr,'accuracy':acc,'precision':prec,'recall':rec,'f1':f1,'cm':cm,'history':h.history})\n",
        "\n",
        "import pandas as pd\n",
        "metrics_df = pd.DataFrame([{k:v for k,v in r.items() if k not in ('cm','history')} for r in results])\n",
        "display(metrics_df.sort_values(['f1','accuracy'], ascending=False))\n",
        "best_idx = metrics_df.sort_values(['f1','accuracy'], ascending=False).index[0]\n",
        "best = results[int(best_idx)]\n",
        "print(f\"Best: optimizer={best['optimizer']}  lr={best['lr']}\")\n",
        "print('Test: ACC={:.3f}  PREC={:.3f}  REC={:.3f}  F1={:.3f}'.format(best['accuracy'],best['precision'],best['recall'],best['f1']))\n",
        "\n",
        "import numpy as np\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.imshow(best['cm'], interpolation='nearest')\n",
        "plt.title('Confusion Matrix (Best Config)')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(2)\n",
        "plt.xticks(tick_marks, ['0','1']); plt.yticks(tick_marks, ['0','1'])\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j, i, int(best['cm'][i, j]), ha='center', va='center')\n",
        "plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
        "plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5) Conclusion (3–5 lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hist = best['history']\n",
        "train_acc_last = hist['accuracy'][-1]\n",
        "val_acc_last = hist['val_accuracy'][-1]\n",
        "gap = train_acc_last - val_acc_last\n",
        "fit_comment = 'Slight overfitting suspected.' if gap > 0.03 else 'No strong signs of overfitting.'\n",
        "print(\n",
        "    f\"Best config: {best['optimizer'].upper()} @ lr={best['lr']}. \"\n",
        "    f\"Test ACC={best['accuracy']:.3f}, PREC={best['precision']:.3f}, REC={best['recall']:.3f}, F1={best['f1']:.3f}. \"\n",
        "    f\"Val acc {val_acc_last:.3f} vs train {train_acc_last:.3f}. {fit_comment}\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "Generated by ChatGPT (Kazi)"
      }
    ],
    "created": "2025-08-20 12:00:18",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

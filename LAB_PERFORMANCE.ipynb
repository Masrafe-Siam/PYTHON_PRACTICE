{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5a66e3",
   "metadata": {},
   "source": [
    "## Bangla Sentiment Analysis Using Random Dataset from Kaggle/hugging face\n",
    "\n",
    "- Dataset: [Link](https://huggingface.co/datasets/khondoker/SentNoB)\n",
    "- Model: BanglaBERT\n",
    "- Description:\n",
    "This lab performance demonstrates a Bangla Sentiment Analysis workflow using a random dataset from Kaggle/Hugging Face and the BanglaBERT model. The process includes installing dependencies, importing libraries, loading and exploring CSV datasets, converting them to Hugging Face datasets, tokenizing with BanglaBERT, converting to TensorFlow datasets, compiling the model, training, evaluating on a test set, and performing predictions. The steps are executed sequentially with outputs shown for each stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8824e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets transformers\n",
    "from datasets import Dataset, load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "817aa9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"Train.csv\")\n",
    "test_df = pd.read_csv(\"Test.csv\")\n",
    "val_df = pd.read_csv(\"Val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88325dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Data  Label\n",
      "0  মুগ্ধ হয়ে গেলাম মামু. আর তোমায় কি কমু. বলো তোম...      1\n",
      "1  এই কুত্তার বাচ্চাদের জন্য দেশটা আজ এমন অবস্তায়...      2\n",
      "2                          ভাই আপনার কথাই যাদু রয়েছে      1\n",
      "3                        উওরটা আমার অনেক ভাল লেগেছে       1\n",
      "4  আমার নিজের গাড়ী নিয়ে কি সাজেক যেতে পারবো না ?...      0\n",
      "                                                Data  Label\n",
      "0  স্বাস্থ্যবান হতে চাই , আমি বয়সের তুলনায় অনেক ব...      0\n",
      "1                        ভাইয়া নতুন ভিডিও আসে না কেন      0\n",
      "2        সৌরভ গাঙ্গুলী ছাড়া দাদাগিরি কখনো জমে উঠত না      0\n",
      "3  ক্রিকেট কে বাচাতে হলে পাপকে অতিশিগ্রিই তাকেও গ...      2\n",
      "4                          আমিতো সেই ঝালপ্রিয়ো মানুষ      1\n",
      "                                                Data  Label\n",
      "0       আর আমার খুবেই আনন্দ লাকছে ভাইটি চাকরি পেয়েছে      1\n",
      "1  ভাই আমাদের আগের মেয়র আনিচুল হক নাই যে আমাদের ক...      2\n",
      "2  আমি মার্ক ওয়েন আর সনির বিশাল ভক্ত । একটা সময় ভ...      1\n",
      "3            ৩ মাস না যেতেই একেকজন ফুলে ফেপে আলুর দম      2\n",
      "4  বাংলাদেশের পুলিশ হলো নিরীহ মানুষের যম , আর অত্...      2\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "print(val_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2feb792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Convert to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "530209bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Masrafe\\Coding\\python\\anaconda\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Masrafe\\Coding\\python\\anaconda\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'electra.embeddings.position_ids', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing TFElectraForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFElectraForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Load Tokenizer and Model\n",
    "model_name = \"csebuetnlp/banglabert\"\n",
    "\n",
    "# Load Tokenizer and Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e9a221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Preprocessing Function\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"Data\"], truncation=True, padding=\"max_length\", max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caa62409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eea5202ec2440a08cf0e45377d156e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12575 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20e06fddd574a76b8b2964e6dd64c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1586 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7457e1610fe94879a591be10bea2e790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1567 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6: Tokenize the Dataset\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e723be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Convert to TensorFlow Datasets (Manual tf.data.Dataset conversion)\n",
    "def convert_to_tf_dataset(encoded_split):\n",
    "    # Convert to list to fix step estimation and batching\n",
    "    input_ids = [example[\"input_ids\"] for example in encoded_split]\n",
    "    attention_mask = [example[\"attention_mask\"] for example in encoded_split]\n",
    "    labels = [example[\"Label\"] for example in encoded_split]\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {\n",
    "            \"input_ids\": tf.convert_to_tensor(input_ids, dtype=tf.int32),\n",
    "            \"attention_mask\": tf.convert_to_tensor(attention_mask, dtype=tf.int32),\n",
    "        },\n",
    "        tf.convert_to_tensor(labels, dtype=tf.int64),\n",
    "    ))\n",
    "\n",
    "    return dataset.shuffle(1000).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_tf_dataset = convert_to_tf_dataset(encoded_dataset[\"train\"])\n",
    "val_tf_dataset = convert_to_tf_dataset(encoded_dataset[\"validation\"])\n",
    "test_tf_dataset = convert_to_tf_dataset(encoded_dataset[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab7a3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Compile the Model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a36fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Masrafe\\Coding\\python\\anaconda\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Masrafe\\Coding\\python\\anaconda\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      " 37/197 [====>.........................] - ETA: 1:22:11 - loss: 1.0710 - accuracy: 0.4003"
     ]
    }
   ],
   "source": [
    "# Step 9: Train the Model\n",
    "model.fit(train_tf_dataset, validation_data=val_tf_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36721605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a TensorFlow SavedModel directory\n",
    "model.save_pretrained(\"my_banglabert_classifier\")\n",
    "tokenizer.save_pretrained(\"my_banglabert_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e430ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Test with an example\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(\"my_banglabert_classifier\")\n",
    "loaded_model = TFAutoModelForSequenceClassification.from_pretrained(\"my_banglabert_classifier\")\n",
    "\n",
    "# Example input\n",
    "test_text = \"আজকের ছবিটি সুন্দর ছিল না তেমন \"\n",
    "\n",
    "# Preprocess the input\n",
    "inputs = loaded_tokenizer(test_text, return_tensors=\"tf\", truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "# Make a prediction\n",
    "outputs = loaded_model(inputs)\n",
    "logits = outputs.logits\n",
    "predicted_class_id = tf.argmax(logits, axis=-1).numpy()[0]\n",
    "\n",
    "# Map the predicted class ID back to a label (assuming 0, 1, 2 correspond to your labels)\n",
    "# You might need to adjust this based on your label mapping\n",
    "label_map = {0: \"Negative\", 1: \"Positive\", 2: \"Neutral\"} # Example mapping, adjust as needed\n",
    "predicted_label = label_map[predicted_class_id]\n",
    "\n",
    "print(f\"Input text: {test_text}\")\n",
    "print(f\"Predicted label ID: {predicted_class_id}\")\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
